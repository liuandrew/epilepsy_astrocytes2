'''
Import necessary packages
'''
import numpy as np
import scipy
import scipy.integrate
import scipy.signal
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib
import pandas as pd
from tqdm import tqdm

import itertools
import os

from ip3_ca_ode_cfg import *
import cfg

#set figure font sizes for readability
font = {'size' : 30,
       'family': 'serif',
       'sans-serif': ['Helvetica']}
matplotlib.rc('font', **font)
matplotlib.rc('text', usetex=True)
color_cycle = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', 
               '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']

diversity_colors = {
#     'SP': '#5dbcd2', #blue
    'SP': '#2b8bfb',
    'PL': 'black',
    'MP': '#b11b1a', #maroon
    'LL': '#cbcae6' #grey
}

'''save figures folder for this section'''
fig_folder = 'figures/paper_plots/diversity/'


'''
------------------------
Experiment Functions
------------------------
These functions will be used to tell use what type of calcium response we have
as well as the IP3 characteristics
'''
def classification_simulation_with_row(df_row, t_0=0, t_f=400, max_step=0.2, input_type='glut',
                                      c_tot=1, poisson_start=False, kpkm=[1, 1]):
    '''
    Run the ip3 simulation with parameters given from pandas dataframe row
    c_tot: control the initial c_tot condition
    poisson_start: whether to use initial condition generated by poisson start
    kpkm: factors to change the kp and km parameters ([30, 10] might be good for correct sensitivity)
    '''
    # all_init = [0.0951442, 34.841184, 0.673079, 0.056767761, 0, 0, 0, 0]
    kp = 0.02
    km = 0.2
    
    if poisson_start:
        load_experiment('poisson/rate_0.2_conc_10')
        cfg.all_init = [cfg.c[-1], cfg.c_tot[-1], cfg.h[-1], cfg.p[-1], cfg.Gstar[-1], cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]
    
#     cfg.all_init[1] = cfg.all_init[1] * c_tot
    cfg.kp = kp * kpkm[0]
    cfg.km = km * kpkm[1]
    
    cfg.A = df_row['A']
    cfg.d_rise = df_row['d_rise']
    cfg.d_decay = df_row['d_decay']
    cfg.r_rise = df_row['r_rise']
    cfg.r_decay = df_row['r_decay']

    if(input_type == 'glut'):
        sol = run_experiment('curve', t_f=t_f, max_step=max_step)
    elif(input_type == 'Gstar'):
        sol = run_Gstar_controlled_experiment('curve', t_f=t_f, max_step=max_step)
    elif(input_type == 'ip3'):
        sol = run_ip3_controlled_experiment('curve', t_f=t_f, max_step=max_step)
        
    # cfg.all_init = all_init
    # cfg.kp = kp
    # cfg.km = km
    
    return sol



def classification_simulation(d_rise, d_decay, r_rise, r_decay, A, t_0=0, t_f=400, max_step=0.2,
                                       input_type='glut'):
    '''
    Run the full system simulation for values to shape glutamate transient
    
    A, d_rise, d_decay, r_rise, r_decay: input curve parameters
    input_type: 'glut'/'ip3' - what system to run control for
    '''
    cfg.A = A
    cfg.d_rise = d_rise
    cfg.d_decay = d_decay
    cfg.r_rise = r_rise
    cfg.r_decay = r_decay
    
    if(input_type == 'glut'):
        sol = run_experiment('curve', t_f=t_f, max_step=max_step)
    elif(input_type == 'ip3'):
        sol = run_ip3_controlled_experiment('curve', t_f=t_f, max_step=max_step, classification=True)
    return sol
    
    
    

        
def diversity_experiment(calibrate=0, progress=False, t_f=150, suite=1):
    '''
    Run set of diversity experiments
    
    calibrate: how to calibrate initial conditions
        0: calibrate to steady state (no input)
        1: calibrate to fixed small input (glut=0.02)
        2: calibrate to fixed small input (noise of 0.03 std dev)
        3: calibrate to fixed oscillations
        4: calibrate to poisson train (glut=2 spike train)
            also fixes Gstar to 0 and cytosolic c to standard steady state
            and decreases initial p, all in order to more reasonable traces
    progress: whether to print progress
    t_f: how long trials are run
    suite:
        1: partial suite (135 trials)
        2: full suite (600 trials)
    '''
    set_init('default')
    cfg.input_max = 0
    run_experiment('pulse', t_f=2000, max_step=10)
    
    c_init = cfg.c[-1]
    Gstar_init = 0
    if calibrate == 0:
        cfg.input_max = 0
        run_experiment('pulse', t_f=1000, max_step=2)
        all_init2 = [c_init, cfg.c_tot[-1], cfg.h[-1], cfg.p[-1], Gstar_init, 
                     cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]
    elif calibrate == 1:
        cfg.input_max = 0.7
        cfg.input_duration = 1000
        run_experiment('pulse', t_f=1000, max_step=2)
        all_init2 = [c_init, cfg.c_tot[-1], cfg.h[-1], cfg.p[-1], Gstar_init, 
                     cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]
    elif calibrate == 2:
        cfg.input_max = 0
        run_experiment('pulse', t_f=1000, max_step=2, noise=0.03)
        all_init2 = [c_init, cfg.c_tot[-1], cfg.h[-1], cfg.p[-1], Gstar_init, 
                     cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]
    elif calibrate == 3:
        cfg.input_max = 4
        cfg.oscillation_on_duration = 2
        cfg.oscillation_off_duration = 100
        run_experiment('oscillation', t_f=1000, max_step=0.5)
        all_init2 = [c_init, cfg.c_tot[-1], cfg.h[-1], cfg.p[-1], Gstar_init, 
                     cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]
    elif calibrate == 4:
        cfg.input_start = 1
        cfg.input_smoothing = 1
        cfg.input_duration = 2
        cfg.input_max = 2
        run_experiment('train', max_step=0.5)
        # all_init2 = [c_init, cfg.c_tot[-1], cfg.h[-1], cfg.p[-1], Gstar_init, 
        #              cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]        
        all_init2 = [c_init, cfg.c_tot[-1], cfg.h[-1], cfg.p[-1]*0.5, Gstar_init, 
                     cfg.Gd1[-1], cfg.Gd2[-1], cfg.lamb[-1]]        
    else:
        set_init('poisson')
        all_init2 = cfg.all_init

        
    cfg.all_init = all_init2
    results_rows = []
    
    if suite == 1:
        ranges = {
            'A': np.array([1, 2, 4, 8, 16]),
            'd_decay': [15, 97, 179],
            'd_rise': [1, 21, 41],
            'r_rise': [0.003, 0.15, 0.8]
        }    
        it = list(itertools.product(ranges['A'], ranges['d_decay'], 
                                           ranges['d_rise'], ranges['r_rise']))
        if progress:
            it = tqdm(it)
            
    elif suite == 2:
        A_range = np.array([1, 2, 4, 8, 16])
        d_decay_range = [15, 56, 97, 138, 179, 220]
        d_rise_range = [1, 11, 21, 31, 41]
        combs = list(itertools.product(A_range, d_decay_range, d_rise_range))
        it = []
        for comb in combs:
            A = comb[0]
            d_decay = comb[1]
            d_rise = comb[2]
            if d_rise < 8:
                r_rise_range = [0.002, 12]
            elif d_rise < 15:
                r_rise_range = [0.002, 0.44, 1.6]
            elif d_rise < 30:
                r_rise_range = [0.002, 0.12, 0.3, 1]
            elif d_rise < 40:
                r_rise_range = [0.003, 0.07, 0.15, 0.3, 0.8]
            else:
                r_rise_range = [0.002, 0.04, 0.09, 0.15, 0.3, 0.8]
            for r_rise in r_rise_range:
                r_decay = compute_r_decay(A, d_decay)

                it.append((A, d_decay, d_rise, r_rise, r_decay))
                
        if progress:
            it = tqdm(it)
                  
    for comb in it:
        cfg.A = comb[0]
        cfg.d_decay = comb[1]
        cfg.d_rise = comb[2]
        cfg.r_rise = comb[3]
        cfg.r_decay = compute_r_decay(cfg.A, cfg.d_decay)
        
        sol = run_experiment('curve', t_f=t_f, max_step=0.5)

        try:
            ip3_amp, ip3_total, ip3_drise, ip3_ddecay = classify_ip3_response()
            Gstar_amp, Gstar_total, Gstar_drise, Gstar_ddecay = classify_ip3_response(cfg.t, cfg.Gstar)
            response_type = calcium_response_classification(cfg.t, cfg.c, peak_priority=True)
            peaks, troughs = calcium_peaks_and_troughs(cfg.t, cfg.c)
            response_characteristics = calcium_response_characteristics(cfg.t, cfg.c, peaks)
        except:
            response_type = 'O (too small)'
            ip3_amp, ip3_total, ip3_drise, ip3_ddecay = [0,0,0,0]
            Gstar_amp, Gstar_total, Gstar_drise, Gstar_ddecay = [0,0,0,0]
            response_characteristics = [0,0,0,0,0,0]

        results_rows.append({
            'A': cfg.A,
            'd_decay': cfg.d_decay,
            'd_rise': cfg.d_rise,
            'r_decay': cfg.r_decay,
            'r_rise': cfg.r_rise,
            'response_type': response_type,
            'response_duration': response_characteristics[2],
            'c_total': response_characteristics[5],
            't': cfg.t,
            'c': cfg.c,
            # 'p': cfg.p,
            'ip3_A': ip3_amp,
            'ip3_drise': ip3_drise,
            'ip3_ddecay': ip3_ddecay,
            'ip3_total': ip3_total,
            'Gstar_A': Gstar_amp,
            'Gstar_drise': Gstar_drise,
            'Gstar_ddecay': Gstar_ddecay,
            'Gstar_total': Gstar_total
        })
    set_init('default')
    return results_rows

'''
------------------------
Classification Functions
------------------------
These functions will be used to tell use what type of calcium response we have
as well as the IP3 characteristics
'''

def ip3_characteristics(t_0, t_f):
    '''
    This function returns some characteristic information about the ip3 curve
    It uses the globally set ip3 curve parameters (d_rise, d_decay, r_rise, r_decay)
    which are set using set_ip3_curve_manual, then ip3_curve_input gives the actual ip3 curve
    
    returns: ip3_total, ip3_amplitude, t_peak, t_duration
    ip3_total: total amount of ip3 in the transient curve
    ip3_amplitude: the height of ip3 at peak
    t_peak: the time of peak
    t_duration: the total time the ip3 transient lasted
    '''
    #get the ip3 curve
    t = np.arange(t_0, t_f, 0.1)
    p = np.zeros(len(t))
    for i in range(len(t)):
        p[i] = ip3_curve_input(t[i])
    
    ip3_total = np.sum(p) / len(p) * t_f #mean instantaneous ip3 multiplied by total time
    
    peaks, _ = scipy.signal.find_peaks(p) #find the index of maximum value of ip3
    if(len(peaks) > 0):
        peak = peaks[0]
    else:
        peak = False
        
    ip3_amplitude = p[peak]
    t_peak = t[peak]
    
    t_start_index = np.argmax(p > 0) #find first occurence that ip3 > 0
    t_end_index = peak + np.argmax(p[peak:] < 0.005) #find first time after the peak that ip3 < 0.005
    t_duration = t[t_end_index] - t[t_start_index]
    
    if(peak == False):
        t_duration = t_f #if there are no peaks, the "duration" is the entire simulation
    
    return ip3_total, ip3_amplitude, t_peak, t_duration
    

def calcium_peaks_and_troughs(t, c, index=True):
    '''
    Determine where the peaks and troughs are in the calcium response
    Pass t and c given by the numerical ODE solver
    index: True/False, if True will return indices of peaks and troughs, rather than values
    
    returns: 
      (index == False): t_peaks, c_peaks, t_troughs, c_troughs
      (index == True): peaks, troughs
    '''
    base_c = c[0]
    response_start_index = np.argmax(c > 1.4 * base_c) #we label the first time the calcium is 1.4 times base level
                                                        #as the start of the calcium response
    peaks, _ = scipy.signal.find_peaks(c) #note that these functions find the indices of peaks and troughs
    peaks = peaks[t[peaks] > cfg.t_star] #real peaks are those that happend after the start of the ip3 signal
    troughs, _ = scipy.signal.find_peaks(-c)
    true_troughs = []
    
    #the only troughs that we should count are the ones that lie between two peaks
    t_first_peak = t[peaks[0]]
    t_last_peak = t[peaks[-1]]
    for trough in troughs:
        if(t_first_peak < t[trough] and t[trough] < t_last_peak):
            true_troughs.append(trough)
    
    if(index):
        return peaks, true_troughs
    else:
        #convert indices to values
        t_peaks = t[peaks]
        c_peaks = c[peaks]
        t_troughs = t[true_troughs]
        c_troughs = c[true_troughs]        
        return t_peaks, c_peaks, t_troughs, c_troughs
    

    
def calcium_response_characteristics(t, c, peaks):
    '''
    Get characteristics of the calcium curve
    '''
    #determine start of calcium response to be 2x the baseline value
    base_c = c[1]
    if base_c > 0.12:
        start_mult = 1.2
    else:
        start_mult = 2
    
    response_start_index = np.argmax(c > start_mult * base_c)
    last_peak = peaks[-1]
    response_end_index = last_peak + np.argmax(c[last_peak:] < start_mult * base_c) #find end of response
    #if always above 2 * baseline value, need to manually set response end as the end of time
    if np.all(c[last_peak:] >= 2 * base_c):
        response_end_index = len(t) - 1
    
    t_response_start = t[response_start_index]
    t_response_end = t[response_end_index]
    t_duration = t_response_end - t_response_start
    
#     base_c = c[response_start_index - 3] #our baseline for calcium is the value of c before response starts
    max_height_c = np.max(c) - base_c
    
    c_means = (c[response_start_index : response_end_index - 1] +\
               c[response_start_index + 1 : response_end_index]) / 2
    c_total = np.sum(np.diff(t[response_start_index : response_end_index]) * c_means)
    
    return response_start_index, response_end_index, t_duration, base_c, max_height_c, c_total
    
    


def visualize_classification(t, c, x_max=150, ret=False, ax=None, peak_priority=False):
    '''
    Visualize what the algorithm is observing to classify a response
    '''
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(8,8))
#     ax.figure(figsize=(8,8))
    ax.plot(t, c)
    ax.plot(t[1:], np.diff(c) / np.diff(t))
    
    vis_dict, response = calcium_response_classification(t, c, vis=True, peak_priority=peak_priority)
    
    if(len(vis_dict['mp_peaks']) > 0):
        ax.scatter(t[vis_dict['mp_peaks']], c[vis_dict['mp_peaks']], c='blue')
    if(len(vis_dict['mp_troughs']) > 0):
        ax.scatter(t[vis_dict['mp_troughs']], c[vis_dict['mp_troughs']], c='red')
    if(vis_dict['end_first_response'] is not None):
        ax.scatter(t[vis_dict['end_first_response']], c[vis_dict['end_first_response']], c='green')
        ax.scatter(t[vis_dict['end_first_response']], [0], c='green')

#     print(t[vis_dict['end_first_response']])
    ax.scatter(t[vis_dict['response_start_index']], c[vis_dict['response_start_index']], c='black')
    ax.scatter(t[vis_dict['response_end_index']], c[vis_dict['response_end_index']], c='black')
    
    ax.plot([0, x_max], [0, 0], '--', c='green')
    ax.set_xlim([0, x_max])
    
    print(response)
    if(ret):
        return vis_dict

    

def calcium_response_classification(t, c, vis=False, peak_priority=True, verbose=False):
    '''
    Classify the type of calcium response given a specific ip3 transient curve
    vis: if this is set to True, at each classification we will instead return a dictionary
        holding the characteristics being used to identify the peak for visualization
        also we will print out information that helps to identify what the algorithm sees
    peak_priority: decide which of two algorithms to use (default to True)
    '''
    
    def conditional_vis_return(response, vis_dict, vis):
        '''
        simple helper function to return the appropriate thing
        '''
        if(vis):
            return vis_dict, response
        else:
            return response
    try:
        ll_duration = 70 #how long the calcium elevation has to be to be classified as long lasting
    #     plt.plot(t, c)
        peaks, troughs = calcium_peaks_and_troughs(t, c)
        response_start_index, response_end_index, t_duration, base_c, max_height_c, c_total =\
                                    calcium_response_characteristics(t, c, peaks)
        # remove peaks that are before response_start_index
        peaks = np.array(peaks)
        peaks = peaks[peaks > response_start_index]
        t_response_start = t[response_start_index]
        t_response_end = t[response_end_index]    
    except:
        return conditional_vis_return('O (too small)', {}, vis)
    
    vis_dict = {
        'response_start_index': response_start_index,
        'response_end_index': response_end_index,
        'mp_peaks': [],
        'mp_troughs': [],
        'end_first_response': None,
        'base_c': base_c
    }
    
    if(len(peaks) == 0):
        #if there are no peaks, no response
        return conditional_vis_return('NR', vis_dict, vis)
    
    if(t_duration > 200):
        #calcium response duration too long
        return conditional_vis_return('O (too long)', vis_dict, vis)
    if(np.max(c[peaks]) < 0.4):
        #calcium peaks are too small
        return conditional_vis_return('O (too small)', vis_dict, vis)
    if(np.max(c[peaks]) > 3.5):
        #calcium peaks are too large
        return conditional_vis_return('O (too large)', vis_dict, vis)
 
    #Indexes for final peaks and troughs after filtering
    mp_peaks = []
    mp_troughs = []

    if peak_priority:
        #with peak priority, we count peaks and troughs differently.
        #troughs are those that reach 50% of the prior peak
        #peaks are those that are above 9% between prior peak and trough
        real_peak_index = 0 #counter for number of peaks besides first found
        for i, peak in enumerate(peaks):
            # print(i, real_peak_index, len(mp_troughs), len(troughs))
            
            #Chunk to add peak to mp_peaks
            if(i == 0):
                #first peak is always real
                mp_peaks.append(peak)
                if verbose:
                    print(f'First peak: ({t[peak]}, {c[peak]})')
            else:
                #check if there is a trough to match the next peak to
                if len(mp_peaks) == len(mp_troughs):
                    trough_c = c[mp_troughs[-1]]
#                     prev_peak_c = c[mp_peaks[-1]]
                    prev_peak_c = c[peaks[i-1]]
                    peak_c = c[peak]
                    
                    #NOTE: computations have used the 0.09 method prior to 1/13/2023, but
                    #maybe 0.35 method with base_c subtracted makes more sense
                    # clear_c_height = 0.09 * (pre_peak_c - trough_c) + trough_c
                    clear_c_height = 0.35 * ((prev_peak_c-base_c) - (trough_c-base_c)) + (trough_c-base_c)
                    if peak_c > clear_c_height:
                        mp_peaks.append(peak)
                        real_peak_index += 1
                        if verbose:
                            print(f'Next peak found tall enough: ({t[peak]}, {c[peak]})')

            
            #Chunk to add troughs to mp_troughs
            if i < len(troughs) and real_peak_index == len(mp_troughs):                
                trough = troughs[i]
                prev_peak_c = c[mp_peaks[real_peak_index]]
                trough_c = c[trough]
                if (trough_c - base_c) < (0.5 * (prev_peak_c - base_c)):
                    #trough reached below 50% of previous valid peak
                    mp_troughs.append(trough)
                    if verbose:
                        print(f'Trough found at <50% height of prev peak: ({t[trough]}, {c[trough]})')
            elif i < len(troughs):
                #If i points to a new trough but there was no mp_peak in between
                #prev_trough and trough, take the lower of the two to be the
                #true trough
                trough = troughs[i]
                trough_c = c[trough]
                prev_trough_c = c[mp_troughs[-1]]
                if trough_c < prev_trough_c:
                    mp_troughs[-1] = trough
                    if verbose:
                        print(f'Replacing previous trough with lower: ({t[trough]}, {c[trough]})')

        
        #Finally go through one more time and only keep troughs that have peaks after
        if verbose and len(mp_troughs) >= len(mp_peaks):
            print('Not enough peaks found to match to each trough, removing extra troughs')
        if verbose:
            print('\n')

        mp_troughs = mp_troughs[:(len(mp_peaks) - 1)]

            
    else:
        #this was the original Marsa algorithm
        #a. for each peak, treat as real if it is >5% of previous peak
        #b. for each trough, treat as real if it is <50% of surrounding peaks
        #real peaks are those that reach >5% of their adjacent peak
#         print(c[peaks])
        for i, peak in enumerate(peaks):
#             print(c[peak] - base_c) 
            real_peak_index = 0
            if(i == 0):
                #the first peak is always real
                mp_peaks.append(peak)
            elif((c[peak] - base_c) > 0.05 * (c[mp_peaks[real_peak_index]] - base_c)):
#                 if(vis):
#                     print('Previous peak {}, next peak {}'.format(
#                         (c[mp_peaks[real_peak_index]], c[peak] - base_c)
#                     ))
#                     print('Previous peak %.2f' % c[mp_peaks[real_peak_index]])
                #otherwise, check is this peak is >5% of the adjacent (real) peak
                mp_peaks.append(peak)
                real_peak_index += 1

        #real troughs are those that reach <50% of their surrounding max peaks
        for i, trough in enumerate(troughs):
            #get the peaks that are to the left and right of each trough
            left_peak = peaks[i]
            right_peak = peaks[i+1]
            if(left_peak in mp_peaks and right_peak in mp_peaks):
                max_peak = np.max([c[left_peak], c[right_peak]]) - base_c
                min_peak = np.min([c[left_peak], c[right_peak]]) - base_c
                if(c[trough] - base_c < 0.5 * min_peak):
                    mp_troughs.append(trough)
    vis_dict['mp_troughs'] = mp_troughs
    vis_dict['mp_peaks'] = mp_peaks

    last_peak = mp_peaks[-1]
    #recalculate reponse end using mp_peaks instead
    _, response_end_index, _, _, _, _ = calcium_response_characteristics(t, c, mp_peaks)
    
    t_response_end = t[response_end_index]
    
    #NOTE: UNSURE IF THIS IS IMPORTANT ATM
#     if(len(mp_troughs) >= len(mp_peaks)):
#         print('Warning: weird case reached')
#     if(len(peaks) > len(mp_peaks)):
#         print('Case: fewer mp_peaks')

    #make a list of times [response_start, mp_troughs, response_end]
    #so we can check if the distance between any of these start/end/trough points
    #is greater than the LL response limit
    
    
    response_checkpoints = np.append(t_response_start, t[mp_troughs])
    response_checkpoints = np.append(response_checkpoints, t_response_end)
    if( (np.diff(response_checkpoints) > ll_duration).any() ):
        if(verbose):
            print('Some response segment was longer than 70s')
        #check if any of these time distances is greater than ll_duration
        return conditional_vis_return('LL', vis_dict, vis)

    
    
    #next we are trying to decide between SP and PL response
    #the major peak duration is the time between response start and the first time
    #the derivative is closest to zero after being negative (after the first peak)
    #or the first peak in c', whichever is sooner
    c_deriv = np.diff(c) / np.diff(t)
    c_neg_deriv = c_deriv[t[1:] > t[peaks[0]]] #this is the c_deriv array starting from after the first peak
    t_neg_deriv = t[t > t[peaks[0]]] #and the corresponding time array
    first_pos_deriv = np.argmax(c_neg_deriv >= 0) #this is the location of the first positive derivative

    #check if deriv never turns positive
    if np.all(c_neg_deriv < 0):
        first_pos_deriv = response_end_index - peaks[0]

    #check for peaks of c_neg_deriv, also can count as end of first response, whichever is first
    c_neg_deriv_peaks = scipy.signal.find_peaks(c_neg_deriv)[0]

    if len(c_neg_deriv_peaks) > 0:
        first_deriv_peak = c_neg_deriv_peaks[0]
        if first_pos_deriv == 0:
            first_pos_deriv = min(first_deriv_peak, response_end_index-peaks[0])
        else:
            first_pos_deriv = min(first_pos_deriv, first_deriv_peak, response_end_index-peaks[0])

    end_first_response = first_pos_deriv + peaks[0]
    t_first_pos = t_neg_deriv[first_pos_deriv] #this is the location in time for first positive derivative

    vis_dict['end_first_response'] = end_first_response
    
    
    
    
    
    if(not peak_priority and len(mp_troughs) > 0):
        if(verbose):
            print('At least one valid trough <50% height of neighboring peaks')
        #otherwise, if we did indeed find any valid troughs and we know the
        #duration is short enough, we have found a MP
        return conditional_vis_return('MP', vis_dict, vis)
    elif(peak_priority and len(mp_peaks) > 1):
        if(verbose):
            print('At least 2 valid peaks')
        return conditional_vis_return('MP', vis_dict, vis)
    else:
        if(verbose):
            print('No valid troughs that were <50% height of neighboring peaks')
#         #now we are in the case that there are no valid troughs, i.e. only 1 valid peak
#         #first check if the whole response stays >15% max response for > ll_duration
#         c_levelled = c - base_c #c_levelled is the calcium response minus the base
#         response_15_index = c_levelled > max_height_c * 0.15
#         t_15 = t[response_15_index]
#         t_15_duration = t_15.max() - t_15.min() #this is the duration that response stays
#                                                 #above 15% of max
#         if(t_15_duration > ll_duration):
#             if(vis):
#                 print('No troughs and the entire reponse stayed about 15% max height for longer than 70s')
#             return conditional_vis_return('LL', vis_dict, vis)
        
        ll_c = c - base_c
        for i, peak in enumerate(mp_peaks):
            ll_c[peak:] = ll_c[peak:] - ((c[peak] - base_c) * 0.15)
            if i > 0:
                ll_c[peak:] = ll_c[peak:] + ((c[mp_peaks[i - 1]] - base_c) * 0.15)
        t_15 = t[ll_c > 0]
        t_15_duration = t_15.max() - t_15.min()
        if(t_15_duration > ll_duration):
            if(verbose):
                print('No troughs and the entire reponse stayed about 15% max height for longer than 70s')
            return conditional_vis_return('LL', vis_dict, vis)
        
        #next we are trying to decide between SP and PL response
        #the major peak duration is the time between response start and the first time
        #the derivative is closest to zero after being negative (after the first peak)
        #or the first peak in c', whichever is sooner
        c_deriv = np.diff(c) / np.diff(t)
        c_neg_deriv = c_deriv[t[1:] > t[peaks[0]]] #this is the c_deriv array starting from after the first peak
        t_neg_deriv = t[t > t[peaks[0]]] #and the corresponding time array
        first_pos_deriv = np.argmax(c_neg_deriv >= 0) #this is the location of the first positive derivative
        
        #check if deriv never turns positive
        if np.all(c_neg_deriv < 0):
            first_pos_deriv = response_end_index - peaks[0]

        #check for peaks of c_neg_deriv, also can count as end of first response, whichever is first
        c_neg_deriv_peaks = scipy.signal.find_peaks(c_neg_deriv)[0]

        if len(c_neg_deriv_peaks) > 0:
            first_deriv_peak = c_neg_deriv_peaks[0]
            if first_pos_deriv == 0:
                first_pos_deriv = min(first_deriv_peak, response_end_index-peaks[0])
            else:
                first_pos_deriv = min(first_pos_deriv, first_deriv_peak, response_end_index-peaks[0])
        
        end_first_response = first_pos_deriv + peaks[0]
        t_first_pos = t_neg_deriv[first_pos_deriv] #this is the location in time for first positive derivative
        
        vis_dict['end_first_response'] = end_first_response
        t_end_first_response = t[end_first_response]
                
        #if the rest of the response never increases beyond 10% of end_first_response
        #then treat end_first_response as the true end response (i.e., SP)
        c_end_first_response = c[end_first_response]
        if np.all(c[end_first_response:] < base_c * 2):
            t_response_end = t_end_first_response
            if(verbose):
                print('Response after inflection too low, treating as SP')


        first_peak_dur = t_end_first_response - t_response_start
        remaining_dur = t_response_end - t_end_first_response
        
        if(verbose):
            print('First response lasted for ' + str(first_peak_dur))
            print('Remaining durations is ' + str(remaining_dur))
        if(remaining_dur > first_peak_dur * 0.5):
            return conditional_vis_return('PL', vis_dict, vis)

        else:
            return conditional_vis_return('SP', vis_dict, vis)
        
    return conditional_vis_return('No Classification', vis_dict, vis)



def find_results_around(results, response_duration, c_total, r_dur_width=5, c_total_width=5):
    '''
    return a section of the results df around a portion of the graph
    '''
    res = results[results['response_duration'] >= response_duration - r_dur_width]
    res = res[res['response_duration'] <= response_duration + r_dur_width]
    res = res[res['c_total'] >= c_total - c_total_width]
    res = res[res['c_total'] <= c_total + c_total_width]
    return res





def classify_ip3_response(t=None, p=None, p_base=None):
    '''
    Get amplitude, total, d_rise and d_decay for an ip3/Gstar curve
    If t and p not given, assume that we are using cfg.t, cfg.p
    For plots with IP3 as an input, a p_base of 0 should be passed in
    '''
    if t is None:
        t = cfg.t
        p = cfg.p
    if p_base is None:
        p_base = cfg.all_init[3]
    peaks = scipy.signal.find_peaks(p)[0]
    peak = peaks[-1]
    amp = np.max(p)
    drise = t[peak]
    #!!end response when reaching within 5% of base
    #end response when reaching 0.05 p
    p2 = p[peak:]
    # response_end = np.argmax(np.abs((p2 - p_base) / amp) < 0.01)
    response_end = np.argmax(p2 < p_base * 1.2)
    if response_end == 0:
        response_end = -1
    else:
        response_end = response_end + peak
    t_response_end = t[response_end]
    ddecay = t_response_end - drise
    total = np.trapz(p, t)
    return amp, total, drise, ddecay




'''
------------------
Plotting Functions
------------------
'''


def diversity_barchart(data, ylim=60, ax=None, legend=True, loc='best', bbox_to_anchor=(0, 0),
                      fontsize=20):
    """Plot barchart showing diversity results

    Args:
        data (dataframe): Pandas dataframe. Ex. 
        results = pd.read_pickle('data/ca_diversity/calibrated/kd1_0.02_kd2_1.2_v3k_0.1_vdelta_0.005')
        ylim (int, optional): Height limit of plot. Defaults to 60.
        ax (axes, optional): Optionally pass a specific matplotlib axes to plot to.
            Defaults to None.
        legend (bool, optional): Optionally add legend. Defaults to True.
        loc (str, optional): Select location of legend. Defaults to 'best'.
        bbox_to_anchor (tuple, optional): Used to set legend outside of axes.
            Defaults to (0, 0).
        fontsize (int, optional): Fontsize. Defaults to 20.
    """
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(12, 10))
        
    num_sp = len(data[data['response_type'] == 'SP'])
    num_pl = len(data[data['response_type'] == 'PL'])
    num_mp = len(data[data['response_type'] == 'MP'])
    num_ll = len(data[data['response_type'] == 'LL'])
    bar_counts = np.array([num_sp, num_pl, num_mp, num_ll])
    scale = np.sum(bar_counts)
    bar_counts = bar_counts / scale * 100
    
    colors = []
    tick_labels = []
    for response in diversity_colors:
        colors.append(diversity_colors[response])
        tick_labels.append(response)
#     colors = ['#2b8bfb', '#040404', '#7e3838', '#90a0b5']
    edge_colors = ['#152c4c', '#4c4c4c', '#403232', '#a49c9c']
#     tick_labels = ['SP', 'PL', 'MP', 'LL']
    ax.bar([0, 1, 2, 3], bar_counts, 0.995, color=colors, edgecolor=edge_colors, tick_label=tick_labels)
    
    if ax is not None:
        ax.set_xlim([-1, 4])
        ax.set_xticks([])
        ax.set_ylim([0, ylim])
        ax.set_yticks(np.arange(0, ylim+1, 20))
    else:
        ax.xlim([-1, 4])
        ax.xticks([])
        ax.ylim([0, ylim])
        ax.yticks(np.arange(0, ylim+1, 20))
    
    for i in range(len(bar_counts)):
        s = str(round(bar_counts[i], 1)) + '\%'
        ax.text(i, bar_counts[i] + 1, s ,horizontalalignment='center', fontsize=fontsize)
        
    if legend:
        handles = [plt.Rectangle((0,0), 1, 1, color=colors[i]) for i in range(4)]
        ax.legend(handles, tick_labels, loc=loc, bbox_to_anchor=bbox_to_anchor)

    
    
    
    
    
def diversity_dotplot(data, ax=None, legend=True, labels=True):
    """Generate a scatter plot of classification results

    Args:
        data (dataframe): Pandas dataframe of classification results
        ax (axes, optional): Optionally pass matplotlib axes to plot to. 
            Defaults to None.
        legend (bool, optional): Optionally create a legend. Defaults to True.
        labels (bool, optional): Optionally add xlabel and ylabel. Defaults to True.
    """
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(10,10))

    for response_type in diversity_colors.keys():
        responses = data[data['response_type'] == response_type]
        ax.scatter(responses['response_duration'], responses['c_total'], color=diversity_colors[response_type], 
                   label=response_type, marker='s', s=20)

    if labels:
        ax.set_xlabel('response duration')
        ax.set_ylabel('total calcium')
        
    if legend:
        ax.legend()




def plot_intermediate_characteristics(results, var='ip3', typ='size', ax=None, s=20, wiggle=False, alpha=1):
    '''
    Plot intermediate characteristics of ip3 or glut and their corresponding identities
    var: 'ip3' or 'Gstar'
    typ: 'size' or 'shape' or 'time'
    '''
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(10, 10))
    
    if typ == 'size':
        for response in diversity_colors:
            r = results[results['response_type'] == response]
            if wiggle:
                noise = np.random.normal(1, 0.01, len(r))
                ax.scatter(r[var + '_A']*noise, r[var + '_total'], c=diversity_colors[response], s=s, alpha=alpha)
            else:
                ax.scatter(r[var + '_A'], r[var + '_total'], c=diversity_colors[response], s=s, alpha=alpha)
    elif typ == 'shape':
        for response in diversity_colors:
            r = results[results['response_type'] == response]
            if wiggle:
                noise = np.random.normal(1, 0.01, len(r))
                ax.scatter(r[var + '_drise']*noise, r[var + '_ddecay'], c=diversity_colors[response], s=s, alpha=alpha)
            else:
                ax.scatter(r[var + '_drise'], r[var + '_ddecay'], c=diversity_colors[response], s=s, alpha=alpha)
                
    elif typ == 'time':
        for response in diversity_colors:
            r = results[results['response_type'] == response]
            if wiggle:
                noise = np.random.normal(1, 0.01, len(r))
                ax.scatter(r[var + '_drise']*noise, r[var + '_ddecay'], c=diversity_colors[response], s=s, alpha=alpha)
            else:
                ax.scatter(r['start'], r['duration'], c=diversity_colors[response], s=s, alpha=alpha)
        

    
    


def visualize_classification(t, c, x_max=150, ret=False, ax=None, verbose=True, peak_priority=False):
    '''
    Visualize what the algorithm is observing to classify a response
    
    Dots:
    blue: peaks
    red: troughs (note often the end of first response is at the same spot
        as the first trough, so we make the red dots bigger so they show from
        underneath)
    green: end of "first response"
    '''
    if ax is None:
        plt.figure(figsize=(8,8))
        ax = plt
    
#     ax.figure(figsize=(8,8))
    ax.plot(t, c)
    ax.plot(t[1:], np.diff(c) / np.diff(t))
    
    vis_dict, response = calcium_response_classification(t, c, vis=True, verbose=verbose, peak_priority=peak_priority)
    
    if(len(vis_dict['mp_peaks']) > 0):
        ax.scatter(t[vis_dict['mp_peaks']], c[vis_dict['mp_peaks']], c='blue')
    if(len(vis_dict['mp_troughs']) > 0):
        ax.scatter(t[vis_dict['mp_troughs']], c[vis_dict['mp_troughs']], c='red', s=100)
    if(vis_dict['end_first_response'] is not None):
        ax.scatter(t[vis_dict['end_first_response']], c[vis_dict['end_first_response']], c='green')
        ax.scatter(t[vis_dict['end_first_response']], [0], c='green')

#     print(t[vis_dict['end_first_response']])
    ax.scatter(t[vis_dict['response_start_index']], c[vis_dict['response_start_index']], c='black')
    ax.scatter(t[vis_dict['response_end_index']], c[vis_dict['response_end_index']], c='black')
    
    ax.plot([0, x_max], [0, 0], '--', c='green')
#     ax.xlim([0, x_max])
    
    if verbose:
        print(response)
    vis_dict['result'] = response
    if(ret):
        return vis_dict
    
    
    
def plot_intermediate_characteristics(results, var='ip3', typ='size', ax=None, s=20, wiggle=False, alpha=1):
    '''
    Plot intermediate characteristics of ip3 or glut and their corresponding identities
    var: 'ip3' or 'Gstar'
    typ: 'size' or 'shape' or 'time'
    '''
    if ax is None:
        fig, ax = plt.subplots(1, 1, figsize=(10, 10))
    
    if typ == 'size':
        for response in diversity_colors:
            r = results[results['response_type'] == response]
            if wiggle:
                noise = np.random.normal(1, 0.01, len(r))
                ax.scatter(r[var + '_A']*noise, r[var + '_total'], c=diversity_colors[response], s=s, alpha=alpha)
            else:
                ax.scatter(r[var + '_A'], r[var + '_total'], c=diversity_colors[response], s=s, alpha=alpha)
    elif typ == 'shape':
        for response in diversity_colors:
            r = results[results['response_type'] == response]
            if wiggle:
                noise = np.random.normal(1, 0.01, len(r))
                ax.scatter(r[var + '_drise']*noise, r[var + '_ddecay'], c=diversity_colors[response], s=s, alpha=alpha)
            else:
                ax.scatter(r[var + '_drise'], r[var + '_ddecay'], c=diversity_colors[response], s=s, alpha=alpha)
                
    elif typ == 'time':
        for response in diversity_colors:
            r = results[results['response_type'] == response]
            if wiggle:
                noise = np.random.normal(1, 0.01, len(r))
                ax.scatter(r[var + '_drise']*noise, r[var + '_ddecay'], c=diversity_colors[response], s=s, alpha=alpha)
            else:
                ax.scatter(r['start'], r['duration'], c=diversity_colors[response], s=s, alpha=alpha)


def reevaluate_diversity(results, peak_priority=True):
    '''rerun calcium response classification algorithm for each row in results'''
    for i in results.index:
        row = results.loc[i]
        t = row['t']
        c = row['c']
        response = calcium_response_classification(t, c, peak_priority=peak_priority)
        results.loc[i, 'response_type'] = response

        
def reevaluate_diversity_folder(folder):
    '''rerun calcium response classification algorithm for each file in a folder
    e.g., in data/ca_diversity/poisson
    '''
    for file in os.listdir(folder):
        results = pd.read_pickle(folder + file)
        reevaluate_diversity(results)
        results.to_pickle(folder + file)
        